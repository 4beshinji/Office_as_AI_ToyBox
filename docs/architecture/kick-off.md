共生型オフィス環境：大規模言語モデルとイベント駆動型エッジアーキテクチャによる自律的管理システムの構築

1. エグゼクティブサマリー

現代のオフィス環境管理は、従来の「自動化（Automation）」から「自律性（Agency）」へとパラダイムシフトの只中にある。既存のビル管理システム（BMS）は、温度センサーの閾値に基づく空調制御のような決定論的なルールベース処理には長けているが、文脈理解や物理的な柔軟性を欠いている。例えば、「窓が開いているため空調効率が低下しているが、外気を取り入れるために意図的に開けられているのか、閉め忘れなのか」といった状況判断や、「ロボットアームがない環境で窓を閉める」といった物理的介入は、従来のシステムでは不可能であった。

本報告書は、この限界を突破するために設計・実装された共生型オフィス環境管理システム（Symbiotic Office Management System: SOMS）のアーキテクチャと実装詳細を包括的に論じる技術研究報告書である。

本システムは、中央知能としてAMD RX 9700（RDNA4、16GB VRAM）上のOllamaで稼働するQwen2.5:14b大規模言語モデル（LLM）を中核に据え、MQTTメッセージバスを神経系として、エッジデバイス（ESP32）と人間を対等な「エージェント」として統合する。Docker Compose上で11サービスが連携し、完全にローカルで動作する自律型オフィス管理基盤を実現した。

特筆すべき技術的特徴は以下の通りである：

**オーケストレーションツールの排除とコードファーストアプローチ**: Node-REDやKubernetesのような重量級のミドルウェアを排除し、Pythonによる非同期イベントループとMQTTプロトコルを用いたシンプルかつ堅牢なイベント駆動型アーキテクチャ（EDA）を採用した。これにより、LLMがシステムの論理構造を直接理解・修正可能な「透明性」を確保している。

**MCP over MQTTプロトコル**: AIモデルとツール間の標準インターフェースであるModel Context Protocol（MCP）を、IoTの標準であるMQTT上に実装し、JSON-RPC 2.0ペイロードによる堅牢なツール呼び出しを実現した。10秒タイムアウトとasyncio.Futureによる非同期応答待ちを組み合わせ、物理デバイスの応答遅延を吸収する。

**視覚的グラウンディング**: YOLOv11（COCO事前学習重み）を用いた画像認識により、在室検知・活動分析・ホワイトボード状態のモニタリングを実現した。プラガブルなモニター設計とYAML設定により、カメラの追加・モニタータイプの変更を再起動なく行える。

**複式簿記経済圏の構築**: スマートホームAPIでは操作不可能な物理タスク（窓閉め、整理整頓等）を解決するため、LLMが報酬（500-5000ポイント）を発行し人間にタスクを依頼する経済システムを実装した。Walletサービスは独立した複式簿記台帳（Double-Entry Ledger）としてPostgreSQLのwalletスキーマ上に構築され、全取引のトレーサビリティを保証する。デバイスXPシステムにより、IoTデバイスの貢献度に応じた動的報酬倍率も実装されている。

**日本語音声合成による対話**: VOICEVOX（ナースロボ_タイプT、speaker_id=47）を用いた日本語音声合成により、タスクアナウンス・完了通知・リジェクション応答を音声で行う。リジェクションストック（最大100件）による事前生成と、デュアルボイス生成（アナウンス+完了の同時生成）により、低レイテンシかつ文脈に沿った音声体験を提供する。

**SensorSwarm 2階層アーキテクチャ**: Hub + Leafの2階層設計により、低コスト・乾電池駆動のLeafデバイスをESP32 Hubが集約しMQTTに橋渡しする。バイナリプロトコル（5-245バイト、MAGIC 0x53、XORチェックサム）と4種のトランスポート（ESP-NOW、UART、I2C、BLEスタブ）で、多様なマイコンプラットフォームに対応する。

本稿は、ハードウェア選定からプロンプトエンジニアリング、通信プロトコル設計、音声合成、経済システム、そして人間行動を促すためのインセンティブ設計に至るまで、実装済みシステムの全領域を網羅した技術研究報告書である。

2. 建築的パラダイム：自動化から自律的エージェンシーへ

2.1 従来のBMSの限界とエージェント型アプローチの必要性

従来のビル管理システム（BMS）は、IF-THEN形式の論理ゲートの集合体である。これは「室温が26度を超えたら冷房を入れる」といった単線的な制御には有効だが、多変量かつ非定型な現実世界の課題には対応できない。例えば、「重要な会議中で静寂が必要なため、室温が高くても空調の風量を下げたい」というニーズや、「CO2濃度が1000ppmを超えているが、在室者が集中作業中のため割り込みの優先度を下げたい」という複合的な判断を、センサーデータのみから推論し適切な行動を選択することはルールベースでは困難である。

本システム SOMS は、システム全体を一つの「有機体」として捉える。LLMが「脳」、MQTTバスが「神経系」、エッジデバイスが「感覚器」および「手足」、そして人間が「高度な外部アクチュエータ」として機能する。このシステムは、事前に定義されたルールに従うのではなく、「環境の快適性とエネルギー効率の最大化」という目的関数に向けて、自律的に思考し、ツールを選択し、行動する。

2.2 イベント駆動型アーキテクチャ（EDA）の採用

本システムでは、Node-REDのようなビジュアルプログラミングツールや、LangChainの複雑なチェーン構造を排し、純粋なPythonコードによる**イベント駆動型アーキテクチャ（EDA）**を採用した。これは以下の理由による。

**レイテンシとスループット**: MQTTブローカーを介したパブ/サブモデルは、HTTPリクエストのようなポーリングオーバーヘッドがなく、ミリ秒単位のリアルタイム通信が可能である。Brainサービスは `office/#`、`hydro/#`、`aqua/#`、`mcp/+/response/#` を購読し、状態変化をイベントとして検出する。

**ハイブリッドトリガー**: Brainの認知サイクルは、30秒間隔のポーリングとMQTTイベント駆動のハイブリッドで起動する。新しいイベントがWorldModelに登録されると `asyncio.Event` がセットされ、3秒のバッチ遅延の後に認知サイクルが開始される。これにより、複数のセンサーが同時に変化した場合も一度の推論サイクルで効率的に処理できる。

**状態の分離**: 各コンポーネント（視覚、推論、制御、音声、経済）は疎結合であり、互いの存在を直接知る必要がない。共通のMQTTトピックおよびREST APIを通じてのみ連携するため、システムの拡張性や保守性が高い。

**LLMとの親和性**: Pythonコードとして記述されたロジックは、テキストベースであるためLLMが解釈しやすく、将来的な「自己修復」や「コード生成による機能拡張」への道を開く。

2.3 システムトポロジー

システムは物理的・論理的に以下の4層で構成される。Docker Compose上の11サービスが協調動作する。

**中央知能層 (Central Intelligence Layer)**:
AMD RX 9700（RDNA4、16GB VRAM）搭載のGPUサーバー。Ollama上でQwen2.5:14b（Q4_K_M量子化）モデルが稼働し、ReActパターンによる高度な推論、タスク計画、自然言語処理を行う。`HSA_OVERRIDE_GFX_VERSION=12.0.1` によるROCm互換性設定でAMD GPUのコンピューティングを有効化している。

**知覚層 (Perception Layer)**:
カメラとYOLOv11モデルによる視覚情報の構造化。3種のプラガブルモニター（OccupancyMonitor、WhiteboardMonitor、ActivityMonitor）が `config/monitors.yaml` で宣言的に設定され、物理世界のアナログ情報をデジタルなJSONデータに変換する。

**神経伝達層 (Communication Layer)**:
MQTTブローカー（Mosquitto）と、その上で動作するMCPブリッジ（JSON-RPC 2.0）。パスワード認証によるアクセス制御を実装。

**物理・人間相互作用層 (Interaction Layer)**:
ESP32によるセンサー・アクチュエータ制御。SensorSwarm Hub+Leafアーキテクチャによる2階層センサーネットワーク。React 19/TypeScript/Vite 7ベースのダッシュボードとVOICEVOX音声合成による人間へのタスク依頼と報酬管理。PostgreSQL上のWalletサービスによる複式簿記経済システム。

3. 中央知能インフラストラクチャ：LLMと推論エンジン

3.1 モデル選定：Qwen2.5の優位性

本システムの中核には、Qwen2.5:14bを採用した。オープンモデルランドスケープにおいて、Qwen2.5は特に以下の点において優位性を持つ。

**命令追従能力 (Instruction Following)**: エージェントシステムにおいて最も重要なのは、OpenAI function-calling schemaを厳密に遵守する能力である。Qwen2.5はコーディングタスクでの高い性能に裏打ちされた論理的整合性を持ち、`tool_calls` フィールドの JSON 出力においてもエラー率が極めて低い。実測ベンチマークでは、12リクエスト連続でツール呼び出し精度100%を達成した。

**多言語対応**: オフィス環境の音声通知は日本語で行われるが、システムプロンプトとツール定義も日本語で記述されている。Qwen2.5の多言語能力により、日本語でのタスクタイトル・説明文の生成品質が高い。

**コンテキストウィンドウ**: 最大128kトークンのコンテキスト長をサポートしており、長時間のセンサーログ、アクティブタスク一覧、30分間のアクション履歴を参照しながらの推論が可能である。

**推論速度**: AMD RX 9700上でのOllama実行において約51 tokens/secの推論速度を達成しており、30秒の認知サイクル間隔に対して十分な応答性能を確保している。

3.2 AMD RX 9700（RDNA4）環境における最適化戦略

本システムのGPU環境はAMD RX 9700（RDNA4、gfx1201、16GB VRAM）である。NVIDIAのCUDAエコシステムとは異なり、ROCm（Radeon Open Compute）スタックを用いる。

3.2.1 量子化 (Quantization)

Qwen2.5:14Bモデルを16GB VRAMに収めるため、**Q4_K_M量子化**を採用した。Ollamaが提供する量子化済みモデル（約9.0GB）により、十分なKVキャッシュ容量を確保しつつ高品質な推論を維持している。

- モデルサイズ: 約9.0GB（Q4_K_M量子化後）
- KVキャッシュ: 残りの約7GBをKVキャッシュおよびランタイムオーバーヘッドに割当
- 推論速度: 約51 tokens/sec
この構成により、推論速度を維持しつつ、数千トークンのコンテキストを保持することが可能となる 。3.2.2 推論エンジン：vLLMの採用推論エンジンにはvLLMを採用する。vLLMのPagedAttentionアルゴリズムは、メモリの断片化を防ぎ、KVキャッシュの利用効率を最大化する。これにより、複数のセンサーやエージェントから同時にリクエストが発生した場合でも、高いスループット（トークン生成速度）を維持できる。また、vLLMはOpenAI互換のAPIエンドポイントを提供するため、開発者は標準的なクライアントライブラリを使用して実装できる利点がある 。3.3 プロンプトエンジニアリング：憲法的AIアプローチLLMを単なるチャットボットから「オフィス管理者」に変貌させるには、強力なシステムプロンプト（System Prompt）が必要である。ここでは「憲法的AI（Constitutional AI）」のアプローチを取り入れ、モデルの行動原理を規定する 。3.3.1 システムプロンプトの構成要素役割定義 (Role Definition): 「あなたは自律型オフィス管理者（AOM）である。あなたの使命は、オフィスの快適性とエネルギー効率を最適化することである。」リソース制約 (Constraints): 「あなたは『クレジット』という有限の予算を持っている。些細なことで人間に依頼して予算を浪費してはならない。」思考プロセス (Chain of Thought): 「行動する前に、必ず状況を分析し、行動のコスト対効果を評価せよ（ReActパターン）。」出力形式 (Output Format): 「思考過程は thought フィールドに、実際の行動は tool_calls としてJSON形式で出力せよ。」3.3.2 構造化出力の強制信頼性を担保するため、LLMの出力はJSONスキーマによって厳格に制御する。vLLMの guided_decoding 機能や outlines ライブラリを使用し、Pydanticモデルで定義されたスキーマに準拠しないトークンの生成を確率的に遮断する。これにより、Python側のパーサーエラーを根絶する 。4. 神経系：MCP over MQTT プロトコル設計4.1 通信プロトコルの選定理由Model Context Protocol (MCP) は、AIモデルがツールやデータソースと対話するための標準仕様であるが、通常はHTTP (SSE) や stdio 上で動作する。しかし、IoT環境においては以下の理由から MQTT が最適である 。非同期性: LLMの推論（数秒）と物理デバイスの動作（数ミリ秒〜数分）の時間的非対称性を、ブローカーがバッファリングすることで吸収できる。軽量性: ヘッダオーバーヘッドが小さく、ESP32のような低リソースデバイスでも容易に実装可能。耐障害性: ネットワーク切断時の再送制御（QoS）や、デバイスの生死監視（LWT: Last Will and Testament）がプロトコルレベルでサポートされている 。4.2 トピック設計と名前空間MQTTのトピック設計は、システムのAPI定義に等しい。本システムでは以下の階層構造を採用する。office/{zone}/{device_type}/{device_id}/{channel}テレメトリ（センサーデータ）:office/meeting_room_a/sensor/env_01/temperature (Payload: 24.5)office/kitchen/camera/cam_02/occupancy (Payload: true)MCP制御チャネル:リクエスト: mcp/{agent_id}/request/{method}レスポンス: mcp/{agent_id}/response/{request_id}4.3 MCP over MQTT パケット構造MCPのJSON-RPCメッセージをMQTTペイロードにカプセル化する。リクエスト（LLM -> Edge）:トピック: mcp/esp32_01/request/call_toolJSON{
  "jsonrpc": "2.0",
  "method": "call_tool",
  "params": {
    "name": "set_led_color",
    "arguments": {"r": 255, "g": 0, "b": 0}
  },
  "id": "req-uuid-12345",
  "meta": {"timestamp": 1700000000}
}
レスポンス（Edge -> LLM）:トピック: mcp/esp32_01/response/req-uuid-12345JSON{
  "jsonrpc": "2.0",
  "result": {
    "content":
  },
  "id": "req-uuid-12345"
}
4.4 Pythonブリッジの実装中央サーバー上では、MQTTブローカーとLLMを繋ぐ MCPブリッジ プログラムが動作する。これは paho-mqtt ライブラリと asyncio を用いて実装される 。動作ロジック:LLMがツール実行を決定すると、ブリッジは一意な request_id を生成し、該当するMQTTトピックへリクエストをPublishする。同時に、request_id をキーとして asyncio.Future オブジェクトを生成し、保留リスト（Pending Map）に保存する。エッジデバイスからのレスポンスが response/# トピックに届くと、ブリッジは request_id を照合し、対応する Future を完了させる。LLMは非同期的に結果を受け取り、推論を再開する。この仕組みにより、LLMは物理デバイスの応答待ち時間中もスレッドをブロックすることなく、他のタスク（例えばダッシュボードからの新規リクエスト処理）を並行して実行できる。5. 視覚的知覚と状態検証システム5.1 視覚の役割：ピクセルから意味へLLMはテキスト（トークン）しか理解できない。画像情報をLLMが扱える形式に変換するのが、知覚層の役割である。単なる物体検出ではなく、「状態（State）」の理解が必要となる 。例えば、「窓がある」ことよりも「窓が開いている」ことの方が、環境管理においては重要である。5.2 YOLOv11による構造化解析YOLOv11 (Ultralytics) は、その高速性と検出精度のバランスから、リアルタイム状態監視に最適である 。5.2.1 カスタムトレーニングとファインチューニング標準のCOCOデータセットには「開いた窓」や「散らかった机」といったクラスは存在しない。したがって、以下の手順でカスタムモデルを構築する。データ収集: オフィス内に設置したカメラから、様々な時間帯・照明条件で画像を収集する（約1000枚）。アノテーション: 単なるバウンディングボックスだけでなく、属性（Attributes）を付与する。Class: Window, Attribute: Open / Closed / AjarClass: CoffeePot, Attribute: Full / Empty学習: YOLOv11s（Smallモデル）をベースに転移学習を行う。これにより、少量のデータでも高い精度を実現する。5.2.2 座標マッピングと空間推論YOLOが出力するのは画像上のピクセル座標 [x1, y1, x2, y2] である。これをLLMが理解できる「意味的空間」にマッピングするロジックをPython側で実装する 。IoU (Intersection over Union) の活用:「人が椅子に座っている」判定: Person のボックスと Chair のボックスの重なり（IoU）が一定値以上であれば Seated と判定。ゾーンマッピング:カメラ画像の座標 (0,0) - (500,500) を「キッチンエリア」、(500,0) - (1000,500) を「ミーティングエリア」と定義した設定ファイルを用意する。YOLOの検出座標がどのゾーンに含まれるかを計算し、JSONに location: "kitchen" などのメタデータを付与する。5.3 視覚的検証ループ（Verification Loop）本システムの核心的な機能の一つが、人間が行ったタスクの視覚的検証である。これはデジタル経済における「Proof of Work（仕事の証明）」に相当する 。タスク完了報告: 人間がダッシュボードで「窓を閉めた」と報告。検証ツール起動: LLMは自動的に verify_state(target="window_01", expected="closed") ツールを呼び出す。画像解析: カメラが最新フレームを取得し、YOLO推論を実行。論理判定:YOLO出力: {"class": "window", "state": "closed", "confidence": 0.95}期待値と一致するため、検証成功（verified: true）を返す。報酬付与: 検証成功に基づき、クレジットが送金される。もし不一致（例：窓がまだ開いている）の場合、LLMは「検証に失敗しました。画像データは窓が開いていることを示しています。再度確認してください」と人間にフィードバックを返す。6. バイオ・デジタル経済圏：人間参加型（HITL）統合6.1 クレジット経済の設計理論スマートホームAPIで操作できない物理的タスク（窓閉め、ホワイトボードの清掃、荷物の移動等）を解決するため、システムは人間を「高度な汎用アクチュエータ」として扱う 。しかし、人間には自由意志があり、命令に従うとは限らない。そこで、**インセンティブ設計（ナッジ理論）**に基づくクレジット経済を導入する。通貨: 「オフィス・クレジット (Office Credit: OC)」原資: システムは毎日一定額（例: 1000 OC）の予算を持つ。価格メカニズム: タスクの難易度と緊急度に応じて、LLMが報酬額を動的に決定する（ダイナミックプライシング）。「窓を閉める（晴れ）」: 10 OC「窓を閉める（豪雨予報・緊急）」: 100 OC交換: 蓄積したクレジットは、デジタルクーポン（QRコード）として発行され、オフィスのコーヒーマシンや売店での軽食と交換できる権利となる。物理的な提供ギミックは不要であり、社会的な契約（Social Contract）として運用される。6.2 React/FastAPIダッシュボードのアーキテクチャ人間とのインターフェースとなるダッシュボードは、リアルタイム性を重視したシングルページアプリケーション（SPA）として構築する 。6.2.1 技術スタックFrontend: React 18, Tailwind CSS, Lucide React (アイコン)。Backend: Python FastAPI。非同期処理に優れ、LLMとの連携が容易 。Real-time: WebSocket (Socket.IO)。新しいタスクが発生した瞬間に、全ユーザーの画面にカードをプッシュ通知する。Database: SQLite。軽量かつトランザクション対応。ユーザー勘定とタスク履歴を管理する 。6.2.2 データベーススキーマ設計信頼性のある経済システムには、整合性の取れた台帳（Ledger）が不可欠である。SQLスキーマ定義:SQL-- ユーザーテーブル
CREATE TABLE users (
    id TEXT PRIMARY KEY,
    username TEXT NOT NULL,
    credit_balance INTEGER DEFAULT 0,
    reputation_score REAL DEFAULT 1.0
);

-- タスクテーブル
CREATE TABLE tasks (
    id TEXT PRIMARY KEY,
    description TEXT NOT NULL,
    bounty_credits INTEGER NOT NULL,
    status TEXT CHECK(status IN ('OPEN', 'ASSIGNED', 'VERIFYING', 'COMPLETED', 'FAILED')),
    assigned_user_id TEXT,
    verification_image_path TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 取引台帳（Ledger）
CREATE TABLE ledger (
    id TEXT PRIMARY KEY,
    user_id TEXT,
    amount INTEGER, -- 正: 獲得, 負: 消費
    transaction_type TEXT, -- 'REWARD', 'PENALTY', 'REDEMPTION'
    reference_task_id TEXT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY(user_id) REFERENCES users(id)
);
このスキーマにより、いつ誰がどのタスクで報酬を得たか、完全な監査証跡（Audit Trail）が残る 。6.3 インタラクションフロータスク生成: LLMが post_human_task ツールを実行。ブロードキャスト: FastAPIがWebSocket経由で全クライアントに NEW_TASK イベントを送信。受注: ユーザーAがスマホで「受注（Accept）」ボタンを押す。排他制御: 最初に押したユーザーに権利が割り当てられ、他ユーザーの画面からは「割当済」となる。実行と報告: ユーザーAがタスクを実行し「完了（Complete）」ボタンを押す。検証と支払: 前述の視覚的検証を経て、SQLiteの users テーブルと ledger テーブルがアトミックに更新される。通知: 「検証完了！ 50クレジットを獲得しました」という通知がユーザーAに届く。7. エッジエンジニアリング：ESP32とRaspberry Piの実装7.1 ESP32による分散制御エッジデバイスには、安価でWi-Fi/Bluetooth機能を内蔵するESP32を採用する。開発効率とメンテナンス性を考慮し、ファームウェアにはMicroPythonを使用する 。7.1.1 MicroPythonファームウェア設計ESP32のコードは極力シンプルに保つ「シン・クライアント（Thin Client）」設計とする。起動時: Wi-Fi接続後、MQTTブローカーに接続し、自身のID（例: esp32_01）に基づくトピック mcp/esp32_01/request/# を購読する。メインループ: メッセージ待ち受け状態（wait_msg）。コマンド処理: 受信したJSONをパースし、method に応じてハードウェア制御関数（machine.Pin.value()等）を呼び出す。フェイルセーフ: ネットワーク切断時は自動的に再接続を試みるウォッチドッグタイマーを実装する。7.1.2 センサー構成DHT22: 温度・湿度測定。BH1750:照度測定（照明制御のため）。HC-SR501: PIR人感センサー（在室検知）。これらのセンサー値は、変化があった場合のみPublishする（Report by Exception）ことで、通信量を削減する。7.2 Raspberry PiによるエッジAIRaspberry Pi 5または4は、カメラサーバーおよびサブゲートウェイとして機能する。役割: USBカメラまたはCSIカメラからの映像取得。処理: 32GB VRAMサーバーへの映像ストリーミング（RTSP）を行うほか、サーバーダウン時には軽量なYOLOv8-Nanoをローカル実行し、最低限の状態監視を継続するバックアップ機能を担う 。8. システムのセキュリティ、安全性、およびプライバシー自律的なエージェントが物理環境を制御するシステムにおいては、安全性への配慮が最優先事項となる。8.1 幻覚（Hallucination）への対策LLMはもっともらしい嘘をつく（幻覚）リスクがある。例えば、存在しないデバイスを操作しようとしたり、危険なほどの高温設定を指示したりする可能性がある。スキーマバリデーション: Pythonブリッジ側で、LLMからの全てのツール呼び出しを厳格に検証する。存在しない device_id や、閾値（例: 設定温度 > 30度）を超えるパラメータは即座に却下し、エラーをLLMにフィードバックする。物理的オーバーライド: 重要なアクチュエータ（電気錠や主電源）には、LLMをバイパスする物理的なスイッチや、従来の火災報知器と連動したハードウェア割り込み回路を設ける。8.2 プライバシー保護カメラ映像の扱いはセンシティブである。オンメモリ処理: YOLOによる解析はRAM上でのみ行い、画像データをディスクに保存しない（検証用の一時スナップショットを除く）。エッジ側での匿名化: Raspberry Pi側で、検出された「人（Person）」領域に対して即座にモザイク処理（Blurring）を施してからサーバーへ送信する設定も可能とする。これにより、サーバー側には個人が特定できない映像のみが渡る。8.3 経済システムの悪用防止ユーザーがタスクを完了せずに報酬を得ようとする「ゲーミング」への対策。視覚的検証の必須化: 前述のYOLO検証なしには報酬支払いを許可しない。信頼スコア（Reputation Score）: ユーザーごとに信頼度（0.0〜1.0）を管理する。検証失敗が続くとスコアが低下し、高額報酬タスクへのアクセス権が制限される 。9. 運用ケーススタディ：「嵐のプロトコル」本システムの真価を示す具体的なシナリオとして、急激な天候悪化時の挙動をシミュレーションする。予兆検知: 外部の天気APIが「15分後に豪雨」を予報。同時に、気圧センサー（BMP280）が急激な気圧低下を検知。状況判断 (LLM): Qwen2.5はコンテキスト情報を統合。「雨による被害のリスクが高い」と判断。状態確認 (Vision): vision_check ツールを一斉実行。YOLOが「窓3と窓5が開いている」と報告。自動化の試行: 窓3にはスマートアクチュエータ（SwitchBot）があるため、API経由で close_window を実行。成功。人間への依頼: 窓5は手動式である。LLMはこれを「高緊急度」と判断し、通常20クレジットの報酬を 100クレジット（特別ボーナス） に引き上げ、post_human_task を実行。タスク名：「【緊急】窓5を至急閉めてください！」。協働: 近くにいた社員Bがスマホ通知を見てタスクを受注、即座に窓を閉める。完了と学習: 視覚検証を経て報酬が支払われる。LLMはログに「悪天候時の人間への依頼は、高額報酬による即応性が有効であった」と記録し、将来の推論に活かす。10. 結論本報告書で詳述した「共生型オフィス環境管理システム」は、LLMの認知能力とIoTの接続性を融合させることで、従来の自動化の限界を超えるアプローチを提示した。特筆すべきは、Node-RED等のGUIツールに依存せず、Pythonコードとプロトコル（MCP over MQTT）によって論理を構成した点にある。これにより、LLM自身がシステムの「API仕様書」を読み解き、状況に応じて柔軟にツールを組み合わせる（Composability）ことが可能となった。また、クレジット経済を通じた人間との協働モデルは、AIが物理世界に干渉するためのラストワンマイルを埋める現実的な解となる。32GB VRAMという比較的身近なハードウェアリソースで実現可能なこのアーキテクチャは、中小規模のオフィスから大規模ビルまで適用可能なスケーラビリティを有しており、次世代のスマートビルディングの標準モデルとなり得るポテンシャルを秘めている。付録：データテーブルと仕様表1: MCP over MQTT トピック・ペイロード定義トピック方向ペイロード例 (JSON)説明mcp/{id}/request/callLLM→Edge{"method": "set_light", "params": {"br": 100}}ツール実行要求mcp/{id}/response/{uuid}Edge→LLM{"result": "ok", "timestamp": 17150000}実行結果返信office/sensor/{id}/tempEdge→LLM{"val": 24.5, "unit": "c"}環境センサー値office/vision/{id}/stateVision→LLM{"window_01": "open", "conf": 0.95}画像認識結果表2: クレジット経済のインセンティブ設計マトリクスタスク種別難易度緊急度基準報酬 (OC)備考照明消灯低低5ついでに行える軽作業窓閉め中中20多少の移動を伴う備品補充中低30在庫確認と運搬が必要緊急対応高高50 - 100豪雨時の窓閉め、こぼれた液体の清掃等このマトリクスはLLMのシステムプロンプト内に記述され、LLMはこの基準に基づいて動的に報酬額を算定する。