services:
  # --- Central Bus ---
  mosquitto:
    image: eclipse-mosquitto:latest
    container_name: soms-mqtt
    restart: always
    ports:
      - "1883:1883" # Exposed for Edge Devices
      - "9001:9001" # Websocket
    volumes:
      - ./mosquitto/mosquitto.conf:/mosquitto/config/mosquitto.conf
      - soms_mqtt_data:/mosquitto/data
      - soms_mqtt_log:/mosquitto/log
    networks:
      - soms-net

  # --- Central Intelligence (Brain) ---
  # NOTE: In a distributed setup, this might run elsewhere.
  # Here we assume it runs alongside the bus.
  brain:
    build: ../services/brain
    container_name: soms-brain
    restart: always
    depends_on:
      - mosquitto
    environment:
      - MQTT_BROKER=mosquitto
      - LOG_LEVEL=INFO
      - LLM_API_URL=http://ollama:11434/v1 # Production with Ollama
      - LLM_MODEL=${LLM_MODEL}
      - SEDENTARY_THRESHOLD_MINUTES=${SEDENTARY_THRESHOLD_MINUTES:-30}
    volumes:
      - ../services/brain/src:/app
    networks:
      - soms-net

  # --- Dashboard Backend ---
  backend:
    build: ../services/dashboard/backend
    container_name: soms-backend
    restart: always
    ports:
      - "8000:8000"
    depends_on:
      - mosquitto
    volumes:
      - ../services/dashboard/backend:/app
      - soms_db_data:/data
    environment:
      - DATABASE_URL=sqlite+aiosqlite:////data/soms.db
      - MQTT_BROKER=mosquitto
    networks:
      - soms-net

  frontend:
    build: ../services/dashboard/frontend
    container_name: soms-frontend
    restart: always
    ports:
      - "80:80"
    depends_on:
      - backend
    networks:
      - soms-net

  # --- VOICEVOX Engine ---
  voicevox:
    build: ../services/voice/voicevox
    container_name: soms-voicevox
    restart: always
    ports:
      - "50021:50021"
    networks:
      - soms-net

  # --- Voice Service ---
  voice-service:
    build: ../services/voice
    container_name: soms-voice
    restart: always
    ports:
      - "8002:8000"
    depends_on:
      - voicevox
    environment:
      - VOICEVOX_URL=http://voicevox:50021
      - LLM_API_URL=http://ollama:11434/v1 # Production with Ollama
      - LLM_MODEL=${LLM_MODEL}
    volumes:
      - ../services/voice/src:/app
      - soms_audio_data:/app/audio
    networks:
      - soms-net
  # --- Local LLM Engine (Ollama) ---
  ollama:
    image: ollama/ollama:rocm
    container_name: soms-ollama
    restart: always
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    environment:
      - HSA_OVERRIDE_GFX_VERSION=12.0.1
    networks:
      - soms-net
  # Using Mock LLM for development/testing (Commented out for Production)
  # Using Mock LLM for development/testing
  mock-llm:
    build: ./mock_llm
    container_name: soms-mock-llm
    restart: unless-stopped
    ports:
      - "8001:8000"
    networks:
      - soms-net
  # --- Perception Node (Optional/Distributed) ---
  # This container needs GPU access if running YOLO locally.
  # perception:
  #   build: ../services/perception
  #   container_name: soms-perception
  #   ...

volumes:
  soms_mqtt_data:
  soms_mqtt_log:
  soms_db_data:
  soms_audio_data:
  ollama_models:


networks:
  soms-net:
    driver: bridge
